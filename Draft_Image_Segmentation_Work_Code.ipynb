{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNS9sajRBc2p+3imULzbwQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lorenzo2812/Master-Thesis-Repository/blob/main/Draft_Image_Segmentation_Work_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMAGE SEGMENTATION TASK: ISIC 2017 DATASET"
      ],
      "metadata": {
        "id": "nnbfZ-ROFRi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMAGE IMPORTING, PRE-PROCESSING AND DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "pWuRQFkl7CU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZING GPU DETAILS"
      ],
      "metadata": {
        "id": "gCubuxN2IZd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "HA57tdSUTX07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRARIES TO BE INSTALLED"
      ],
      "metadata": {
        "id": "Ast-c7nDDpjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR DATA AUGMENTATION\n",
        "!pip install imgaug\n",
        "#FOR HYPERPARAMETERS TUNING\n",
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "lG6c03rfvo1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIBRARIES TO BE IMPORTED"
      ],
      "metadata": {
        "id": "41jo-mliIdra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras import layers,models\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from keras.utils import plot_model\n",
        "import pydot\n",
        "import graphviz\n",
        "import pydotplus\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.utils import to_categorical\n",
        "import shutil\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "import time\n",
        "import imgaug.augmenters as iaa\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from keras_tuner import HyperModel, Hyperband, Objective\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from keras.models import load_model\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage"
      ],
      "metadata": {
        "id": "7l-qlu_XTjCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONNECTING TO GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "sx7grxi_Dztl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')   #capability to navigate through my drive folders\n"
      ],
      "metadata": {
        "id": "AdfXrCOkTcaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA UPLOADING, RESIZING, CONVERTING TO GRAYSCALE AND NORMALIZING"
      ],
      "metadata": {
        "id": "b9BrBzicrEvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-processing the data: all folders of data imported from google drive: /content/drive\n",
        "train_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Training_Data'\n",
        "train_mask_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Training_Part1_GroundTruth'\n",
        "validation_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Validation_Data'\n",
        "validation_mask_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Validation_Part1_GroundTruth'\n",
        "test_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Test_Data'\n",
        "test_mask_data_path = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Test_Part1_GroundTruth'\n",
        "img_size = 256  #common image size I want to use: since higher resolution can lead to better performance this size could be more appropriate than 64\n",
        "\n",
        "def create_data(path): #DATA PRE-PROCESS CUSTOMIZED FUNCTION\n",
        "    data = [] #this list will store the output data\n",
        "    error_count = 0\n",
        "    total_time = 0\n",
        "    num_images = 0\n",
        "\n",
        "    image_files = sorted(os.listdir(path))\n",
        "\n",
        "    for img in image_files:\n",
        "        start_time = time.time()  #I want to monitor the time I will need to read and process my data\n",
        "        try:\n",
        "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # images to be read in grayscale\n",
        "            if img_arr is None:\n",
        "                print(f\"Failed to load image: {os.path.join(path, img)}\")\n",
        "                error_count += 1\n",
        "                continue\n",
        "            resized_arr = cv2.resize(img_arr, (img_size, img_size))  # image resizing process\n",
        "            data.append(resized_arr)\n",
        "            num_images += 1\n",
        "            print(f\"Image {img} loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {os.path.join(path, img)} - {e}\")\n",
        "            error_count += 1\n",
        "        end_time = time.time()\n",
        "        total_time += (end_time - start_time)\n",
        "\n",
        "    print(f\"Number of images loaded: {len(data)}\")\n",
        "    print(f\"Number of images with errors: {error_count}\")\n",
        "    print(f\"Total time taken: {total_time:.2f} seconds\")\n",
        "    if num_images > 0:\n",
        "        print(f\"Average time per image: {total_time / num_images:.2f} seconds\")   #average time image loading\n",
        "\n",
        "    return np.array(data) / 255.0  # normalizing my data after converting the list storing it into and array: I obtain that every pixel has a value between 0 and 1\n",
        "\n",
        "#applying the function on all my data\n",
        "train_data = create_data(train_data_path)\n",
        "train_mask = create_data(train_mask_data_path)\n",
        "validation_data = create_data(validation_data_path)\n",
        "validation_mask = create_data(validation_mask_data_path)\n",
        "test_data = create_data(test_data_path)\n",
        "test_mask = create_data(test_mask_data_path)\n"
      ],
      "metadata": {
        "id": "cXAPXtQ9ZHuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nr of images for set of data downloaded\n",
        "print(f\"Number of elements in train_data: {len(train_data)}\")\n",
        "print(f\"Number of elements in train_mask: {len(train_mask)}\")\n",
        "print(f\"Number of elements in validation_data: {len(validation_data)}\")\n",
        "print(f\"Number of elements in validation_mask: {len(validation_mask)}\")\n",
        "print(f\"Number of elements in test_data: {len(test_data)}\")\n",
        "print(f\"Number of elements in test_mask: {len(test_mask)}\")"
      ],
      "metadata": {
        "id": "oViwryisaFhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING ARRAYS RELATED TO THE IMAGES LOADED AND PRE-PROCESSED"
      ],
      "metadata": {
        "id": "bWkSSkiabABs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving all the pre-processed images\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/train_data.npy', train_data)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/train_mask.npy', train_mask)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/validation_data.npy', validation_data)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/validation_mask.npy', validation_mask)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/test_data.npy', test_data)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/test_mask.npy', test_mask)"
      ],
      "metadata": {
        "id": "xGBgT1FbbFxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE ARRAYS SAVED BEFORE: THESE PROCESS CAN BE DONE TO AVOID APPLYING THE CREATE DATA FUNCTION EVERY TIME A NEW SESSION BEGINS"
      ],
      "metadata": {
        "id": "1SLE4Bu8EMOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the arrays saved: to skip previous step for next session\n",
        "train_data=np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/train_data.npy')\n",
        "train_mask=np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/train_mask.npy')\n",
        "validation_data = np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/validation_data.npy')\n",
        "validation_mask = np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/validation_mask.npy')\n",
        "test_data = np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/test_data.npy')\n",
        "test_mask = np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/test_mask.npy')"
      ],
      "metadata": {
        "id": "2MnfQL0Jku9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE OF GRAYSCALE IMAGES AND SEGMENTATION MASKS LOADED"
      ],
      "metadata": {
        "id": "JEMv0n46R9gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of array with train data\n",
        "train_data.shape"
      ],
      "metadata": {
        "id": "TzJcvIctQDr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting an image of example\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(train_data[160], cmap='gray')\n",
        "plt.title('Example Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lnf9IgFcVhxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a mask of example\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(train_mask[160], cmap='gray')\n",
        "plt.title('Example Mask')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n_CurAhgVoBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA AUGMENTATION: TO EXPAND THE DATASET, TRAIN DATA HAS BEEN AUGMENTED BY 5 TIMES, APPLYING DIFFERENT TRANFORMATIONS TO ORIGINAL DATA"
      ],
      "metadata": {
        "id": "5wm_YqDDq_5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PURPOSE: INCREASING VARIABILITY AND REDUCING OVERFITTING BY INTRODUCING TRANSFORMED VERSIONS OF MY TRAINING DATA TO EXPAND MY DATASET\n",
        "\n",
        "#Defining the augmentation sequence\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),  # horizontal flips(50% images)\n",
        "    iaa.Crop(percent=(0, 0.1)),  # random crops  (frpm 0 to 10% of the image)\n",
        "    iaa.LinearContrast((0.75, 1.5)),  # contrast changes\n",
        "    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),  # add gaussian noise to simulate imperfections (from 0 to 5% of the pixel)\n",
        "    iaa.Multiply((0.8, 1.2)),  # brightness changes\n",
        "    iaa.Affine(\n",
        "        rotate=(-25, 25),  # rotate by -25 to +25 degrees\n",
        "        shear=(-8, 8)  # shear by -8 to +8 degrees (distorsion along the axis)\n",
        "    )\n",
        "])\n",
        "\n",
        "# Path to my dataset\n",
        "input_images_dir = train_data_path\n",
        "input_masks_dir = train_mask_data_path\n",
        "output_images_dir = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Augmented_Data'           #PATHS WHERE IMAGES AND MASKS AUGMENTED WILL BE SAVED\n",
        "output_masks_dir = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Augmented_Masks'\n",
        "\n",
        "# Number of augmented images to generate per original image: augmenting the dataset by 5 times: to every image corresponds 5 augmented images\n",
        "num_augmented_images = 5\n",
        "\n",
        "# Create output directories to store augmented data\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "os.makedirs(output_masks_dir, exist_ok=True)\n",
        "\n",
        "# Loop over all images in the dataset\n",
        "for filename in os.listdir(input_images_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'): #both if i've jpg and png\n",
        "        image = imageio.imread(os.path.join(input_images_dir, filename))\n",
        "\n",
        "        for i in range(num_augmented_images):\n",
        "            image_aug = seq(image=image) #applying function with transformation sequence\n",
        "\n",
        "            # Save augmented images\n",
        "            output_image_path = os.path.join(output_images_dir, f'aug_{i}_{filename}')\n",
        "            imageio.imwrite(output_image_path, image_aug)\n",
        "            print(f'{i} Image {filename} augmented successfully as {output_image_path}')\n",
        "\n",
        "#same process for masks\n",
        "for filename in os.listdir(input_masks_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        # Read the mask\n",
        "        mask = imageio.imread(os.path.join(input_masks_dir, filename))\n",
        "\n",
        "        # Wrap the mask in SegmentationMapsOnImage\n",
        "        segmap = SegmentationMapsOnImage(mask, shape=mask.shape) #specific function for masks: helps mantaining the characteristics of these specific kind of images (which have also discrete values for diff regions and not continuous like regular color images)\n",
        "\n",
        "        for i in range(num_augmented_images):\n",
        "\n",
        "            segmap_aug = seq(segmentation_maps=segmap) #applying function with transformation sequence\n",
        "\n",
        "            # Extract the augmented mask\n",
        "            mask_aug = segmap_aug.get_arr()\n",
        "\n",
        "            # Save the augmented mask\n",
        "            output_mask_path = os.path.join(output_masks_dir, f'aug_{i}_{filename}')\n",
        "            imageio.imwrite(output_mask_path, mask_aug)\n",
        "            print(f'{i} Mask {filename} augmented successfully as {output_mask_path}')\n",
        "\n",
        "print(\"Data augmentation for image segmentation completed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8qfbbwhDrPuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "APPLYING ALL THE PRE-PROCESSING STEPS TO AUGMENTED IMAGES AND MASKS, LIKE I DID WITH TRAINING DATA"
      ],
      "metadata": {
        "id": "urqBjj0dGYzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE DATA FOR AUGMENTED DATA\n",
        "output_images_dir = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Augmented_Data'\n",
        "augmented_images=create_data(output_images_dir)"
      ],
      "metadata": {
        "id": "R0SAt5x-Ztg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE DATA FOR AUGMENTED MASKS\n",
        "output_masks_dir = '/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/ISIC-2017_Augmented_Masks'\n",
        "augmented_masks=create_data(output_masks_dir)"
      ],
      "metadata": {
        "id": "tdygefQQFthg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAVING THE ARRAYS\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/augmented_images.npy', augmented_images)\n",
        "np.save('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/augmented_masks.npy', augmented_masks)"
      ],
      "metadata": {
        "id": "6ClgHDfbFu7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOADING THE ARRAYS SAVED: TO SKIP THE PRE-PROCESSING STEPS EVEN FOR MY AUGMENTED DATA\n",
        "augmented_images=np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/augmented_images.npy')\n",
        "augmented_masks=np.load('/content/drive/MyDrive/TESI SU SEGMENTAZIONE IMMAGINI (ISIC 2017)/augmented_masks.npy')"
      ],
      "metadata": {
        "id": "korTKqmspJ7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOTTING AN AUGMENTED IMAGE: AN EXAMPLE\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(augmented_images[4000], cmap='gray')\n",
        "plt.title('Example Image: Augmented')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FH-e0SPhwNPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOTTING AN AUGMENTED MASK: AN EXAMPLE\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(augmented_masks[0], cmap='gray')\n",
        "plt.title('Example Mask: Augmented')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "82rjfYYSwSkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMBINING TRAINING AND AUGMENTED DATA IN THE DATASET:  A NEW TRAINING SET 6 TIMES THE SIZE OF THE PREVIOUS ONE"
      ],
      "metadata": {
        "id": "vhCcSbO_G5v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_images = np.concatenate((train_data, augmented_images), axis=0)\n",
        "\n",
        "train_data_masks = np.concatenate((train_mask, augmented_masks), axis=0)\n",
        "\n",
        "print(\"Combined data images contains\", len(train_data_images), \"images.\")\n",
        "\n",
        "print(\"Combined data masks contains\", len(train_data_masks), \"masks.\")"
      ],
      "metadata": {
        "id": "EYRdTN2-bpYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EXPANDING ARRAYS\n",
        "train_data_images = np.expand_dims(train_data_images, axis=-1)\n",
        "train_data_masks = np.expand_dims(train_data_masks, axis=-1)\n",
        "validation_data= np.expand_dims(validation_data, axis=-1)\n",
        "validation_mask = np.expand_dims(validation_mask, axis=-1)\n",
        "test_data = np.expand_dims(test_data, axis=-1)\n",
        "test_mask = np.expand_dims(test_mask, axis=-1)"
      ],
      "metadata": {
        "id": "oBkoCrCUyuXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW TRAIN DATA SIZE (CONTAINING EVEN AUGMENTED ONES)\n",
        "train_data_images.shape\n",
        "train_data_masks.shape"
      ],
      "metadata": {
        "id": "ay8Fnw4ty1W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-NET ARCHITECTURE"
      ],
      "metadata": {
        "id": "mAhr27oewF5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING COSTUMIZED FORMULA TO USE DICE COEFFICIENT AS A METRICS"
      ],
      "metadata": {
        "id": "g3G99IGpHX2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(y_true, y_pred):  #FUNCTION TAKING GROUND TRUTH LABELS AND PREDICTED LABELS  (LABELS ARE 1 AND 0: BINARY SEGMENTATION MASKS)\n",
        "    smooth = 1.   #SMALL COSTANT ADDED TO AVOID DIVIDING BY ZERO\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)  #FLATTENING LABELS TO 1 D ARRAY FOR BOTH TRUE AND PREDICTED\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f) #INTERSECTION OF TRUE AND PREDICTED LABELS\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)   #DICE COEFF FORMULA MEASURING OVERLAP BETWEEN TRUE AND PREDICTED LABELS\n",
        "\n",
        "\n",
        "\n",
        "class DiceCoefficient(keras.metrics.Metric):  #CLASS INERITHING FROM  keras.metrics.Metric\n",
        "    def __init__(self, name='dice_coefficient', **kwargs): #CLASS INITIALISATION AND EVENTUAL ARGUMENTS\n",
        "        super(DiceCoefficient, self).__init__(name=name, **kwargs) #INITIALISER CALCULATION OF THE PARENT CLASS\n",
        "        self.dice = self.add_weight(name='dc', initializer='zeros') #WEIGHT VARIABLE INITIALISED TO ZERO ADDED\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):  #METHOD TO UPDATE STATE OF THE METRIC\n",
        "        dice = dice_coefficient(y_true, y_pred) #CALCULATING DICE COEFF\n",
        "        self.dice.assign(dice)  #UPDATING DICE WEIGHT WITH CALCUATED COEFF\n",
        "\n",
        "    def result(self):\n",
        "        return tf.cast(self.dice, tf.float32)  #RETURNING A DICE WEIGHT WITH THAT DATATYPE\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.dice.assign(0.0) #RESETTING DICE TO 0\n",
        "\n"
      ],
      "metadata": {
        "id": "475xyc313gp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING COSTUMIZED FORMULA TO USE JACCARD COEFFICIENT AS A METRICS"
      ],
      "metadata": {
        "id": "_SoLrW9sHmPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_coefficient(y_true, y_pred):  #SAME OPERATIONS THAN DICE BUT THIS TIME I DEFINE BOTHE INTERSECTION AND UNION SINCE I NEED BOTH IN THE FORMULA\n",
        "    smooth = 1.\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "class JaccardCoefficient(keras.metrics.Metric):\n",
        "    def __init__(self, name='jaccard_coefficient', **kwargs):\n",
        "        super(JaccardCoefficient, self).__init__(name=name, **kwargs)\n",
        "        self.jaccard = self.add_weight(name='jc', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        jaccard = jaccard_coefficient(y_true, y_pred)\n",
        "        self.jaccard.assign(jaccard)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.cast(self.jaccard, tf.float32)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.jaccard.assign(0.0)\n"
      ],
      "metadata": {
        "id": "rL8RP0RJHkUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING THE ARCHITECTURE WITH HYPERPARAMETERS CHOSEN TO BE TUNED"
      ],
      "metadata": {
        "id": "_SqBQwF0HtPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetHyperModel(HyperModel): #NEW CLASS INHERITING THE HYPERMODEL, A CLASS USED TO BUILD U NET WITH HYPERPARAMETERS TUNING\n",
        "    def build(self, hp):\n",
        "        inputs = keras.Input(shape=(256, 256,1)) #INPUT:GRAYSCALE IMAGES 256X256\n",
        "\n",
        "        # Encoder: hyp tuned: NR LAYERS, FILTERS SIZE PER LAYER, KERNEL SIZE PER LAYER, DROPOUT\n",
        "        x = inputs #initialisation of inputs to build the encoder\n",
        "        for i in range(hp.Int('num_layers', 3, 5)):  #in the encoder there'll be between 2 and 5 layers(hyperparam num layers encoder) #and there'll be looping over them\n",
        "            x = keras.layers.Conv2D(              #2 D conv layer added\n",
        "                filters=hp.Int(f'filters_{i}', 32, 256, step=32),  #filters from 32 to 256 in steps of 32\n",
        "                kernel_size=hp.Choice(f'kernel_size_{i}', [3, 5]), #kernel hyperparameter\n",
        "                activation='relu',\n",
        "                padding='same' #output must have same width and height than input\n",
        "            )(x)\n",
        "            x = keras.layers.Dropout(hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.1))(x) #dropout other hyperparameter (OVERFITTING PREVENTION): from 0 to 0.5 in steps of 0.1: for every conv2d layer there'll be a dropout\n",
        "            x = keras.layers.MaxPooling2D()(x) #maxpooling layer: for every conv2d layer there'll be one (TO REDUCE SPATIAL DIMENSION OF FEATURE MAPS)\n",
        "\n",
        "        # Bottleneck #just one conv 2d added, with following hyperparamters to tune: filters (like before but with steps of 64)\n",
        "        x = keras.layers.Conv2D(\n",
        "            filters=hp.Int('bottleneck_filters', 256, 512, step=64),\n",
        "            kernel_size=hp.Choice('bottleneck_kernel_size', [3, 5]),\n",
        "            activation='relu',\n",
        "            padding='same'\n",
        "        )(x)\n",
        "\n",
        "        # Decoder #same hp tuning strategy\n",
        "        for i in range(hp.Int('num_layers', 3, 5)):\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                filters=hp.Int(f'decoder_filters_{i}', 32, 256, step=32),\n",
        "                kernel_size=hp.Choice(f'decoder_kernel_size_{i}', [3, 5]),\n",
        "                activation='relu',\n",
        "                padding='same'\n",
        "            )(x)\n",
        "            x = keras.layers.Dropout(hp.Float(f'decoder_dropout_{i}', 0.0, 0.5, step=0.1))(x)\n",
        "            x = keras.layers.UpSampling2D()(x)  #upsampling TO INCREASE SPATIAL DIMENSIONS OF FEATURE MAPS\n",
        "\n",
        "        outputs = keras.layers.Conv2D(  #FINAL CONV LAYER FOR THE OUTPUT\n",
        "            filters=1,\n",
        "            kernel_size=1,\n",
        "            activation='sigmoid' #SIGMOID CAUSE I NEED PROBABILITIES, PROBABILITY FOR A PIXEL TO BE 0 OR 1\n",
        "        )(x)\n",
        "\n",
        "        model = keras.Model(inputs, outputs) #KERAS MODEL CREATED WITH THE SPECIFIED INPUTS AND OUTPUTS\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(  #ADAM OPTIMIZER\n",
        "                hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4]) #ANOTHER HYPERPARAMETER: LEARNING RATE\n",
        "            ),\n",
        "            loss='binary_crossentropy',  #BINARY SEGM MASKS: BINARY CROSS ENTROPY\n",
        "            metrics=[JaccardCoefficient()] #MY METRIC USED TO EVALUATE THE MODEL\n",
        "        )\n",
        "        return model"
      ],
      "metadata": {
        "id": "oR5lnnl0z3Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING THE OBJECT AND THE TUNER"
      ],
      "metadata": {
        "id": "azjBUQNrH2HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = UNetHyperModel() #INSTANCE CREATION FOR THE CLASS UNETHYPERMODEL PREVIOSULY CREATED\n",
        "\n",
        "tuner = Hyperband( #HYPERBAND TUNER ALGORITHM\n",
        "    hypermodel, #MODEL TO BE TUNED\n",
        "    objective=Objective(\"val_jaccard_coefficient\", direction=\"max\"), #OBJECTIVE IS MAXIMIZING JACCARD COEFF\n",
        "    max_epochs=100, #MAX EPOCH PER MODEL\n",
        "    factor=5, #REDUCTION FACTOR\n",
        "    directory='Work directory', #DIR TO SAVE\n",
        "    project_name='unet_tuning'\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)  #TRAINING WILL STOP IF THERE'RE 5 EPOCHS WITH NO IMPROVEMENT IN VALIDATION LOSS"
      ],
      "metadata": {
        "id": "dDZQhy8g0rFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "APPLYING THE ALGORITHM TO MY DATA, TO FIND THE BEST COMBINATION OF HYPERPARAMETERS"
      ],
      "metadata": {
        "id": "STMhMwnwt2lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I use checkpoint to stop the training everytime i want and I can get the best model till that point\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='best_model.h5',  # Path where the model will be saved\n",
        "    monitor='val_loss',        # Metric to monitor\n",
        "    save_best_only=True,       # Save only the best model\n",
        "    mode='min'                 # Mode for the monitored metric\n",
        ")"
      ],
      "metadata": {
        "id": "eIoID7B3e6Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_data_images, train_data_masks, epochs=100, batch_size=32, validation_data=(validation_data, validation_mask),  callbacks=[checkpoint_callback] )\n",
        "#Hyperband tuning process: goal to find best hyperparameters combination by maximizing jaccard coeff"
      ],
      "metadata": {
        "id": "I8hzHfE-0sUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GETTING BEST MODEL"
      ],
      "metadata": {
        "id": "SRSxnWAxIiXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]   #RETRIEVING ONE MODE, THE TOP 1 (FIRST FROM THE LIST): BEST MODEL FOUND DURING HYPER PARAM TUNING"
      ],
      "metadata": {
        "id": "mOYThENG0vkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOADING THE BEST MODEL, TO USE IT AGAIN EVEN WHEN THIS SESSION IS OVER"
      ],
      "metadata": {
        "id": "Zyxx88QKIckg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "8b6MtCugLz7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary() #detailed summary of the modelâ€™s architecture, including the layers, output shapes, and the number of parameters."
      ],
      "metadata": {
        "id": "f3HvKYqs59Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FITTING THE BEST MODEL"
      ],
      "metadata": {
        "id": "gNlQVf-r9zdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[JaccardCoefficient()]\n",
        ")"
      ],
      "metadata": {
        "id": "0xN3ZocS96na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining train and validation data for fitting the best model\n",
        "combined_data = np.concatenate((train_data_images, validation_data))\n",
        "combined_masks = np.concatenate((train_data_masks, validation_mask))"
      ],
      "metadata": {
        "id": "4rPINbpKFqYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=best_model.fit(combined_data, combined_masks, epochs=100)"
      ],
      "metadata": {
        "id": "IAJeO1OrF5HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOTTING THE JACCARD INDEX (OR OTHERE METRIC) OVER EPOCHS GRAPH"
      ],
      "metadata": {
        "id": "B_US-i0hGIYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Over Epochs')\n",
        "\n",
        "# Plot the training and validation metric of my best model over epochs\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['jaccard_coefficient'], label='Training Jaccard Coefficient')\n",
        "plt.plot(history.history['val_jaccard_coefficient'], label='Validation Jaccard Coefficient')\n",
        "plt.legend()\n",
        "plt.title('Jaccard Coefficient Over Epochs')\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SlfHU2BvGF6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATING THE MODEL ON TEST DATA"
      ],
      "metadata": {
        "id": "7xQ8OVmiItTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_model.evaluate(test_data, test_mask)  #BEST MODEL EVALUATED ON TEST DATA\n",
        "print(results)"
      ],
      "metadata": {
        "id": "gVkplxZA6Pqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZING PREDICTED MASKS TO COMPARE THEM WITH THE INPUT ONES"
      ],
      "metadata": {
        "id": "uPl7l6HxIw0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #VISUALIZING PREDICTIONS ON TEST DATA AND COMPARING WITH THE REAL MASKS\n",
        "def visualize_predictions(model, test_images, test_masks, num_images=5):\n",
        "    predictions = model.predict(test_images)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(test_images[i].squeeze(), cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        # True mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(test_masks[i].squeeze(), cmap='gray')\n",
        "        plt.title('True Mask')\n",
        "\n",
        "        # Predicted mask\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "visualize_predictions(best_model, test_data, test_mask)\n"
      ],
      "metadata": {
        "id": "fhbkGcnBFNJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZING ALL OTHER RELEVANT METRICS FOR MY BEST MODEL"
      ],
      "metadata": {
        "id": "2geaGeTohjrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(test_data)\n",
        "accuracy = accuracy_score(test_mask, predictions)\n",
        "precision = precision_score(test_mask, predictions)\n",
        "recall = recall_score(test_mask, predictions)\n",
        "f1 = f1_score(test_mask, predictions)\n",
        "auc = roc_auc_score(test_mask, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'AUC: {auc}')\n"
      ],
      "metadata": {
        "id": "aIK3Z99rf6Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "G5qOdihBiMNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_true = test_mask.flatten() #flattening is necessary cause we need a 1D array\n",
        "img_pred = (predictions > 0.5).astype(int).flatten()   #predicted probabilities converted as binary values: i will end with a flattened array with 1 or 0 (int values)\n",
        "cm = confusion_matrix(img_true, img_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Background', 'Object'], yticklabels=['Background', 'Object'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix for Binary Segmentation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7iA7dJvAnMh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}